version: 0.2
#https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html

#####
# Performs an infrastructure deployment.
# For Code Deployments see CircleCI and AWS CodeDeploy
#####

env:
  shell: /bin/bash
  variables:
    #Terraform workspace that we operate in
    TF_DEV_WORKSPACE: Dev
    TF_WORKSPACE: Prod
    #The ref of the main branch we work against
    MAIN_BRANCH: 'refs/heads/main'
    #The ref of the dev branch we work against
    DEV_BRANCH: 'refs/heads/dev'
    #Metaflow requires a username to run
    USERNAME: 'codebuild'
  secrets-manager:
    #Pull in the default terraform cloud token
    TERRAFORM_TOKEN: 'CodeBuild/Default:terraform_token'
    PAGERDUTY_TOKEN: 'CodeBuild/Default:pagerduty_token'
    GITHUB_ACCESS_TOKEN: 'CodeBuild/Default:github_access_token'

    # Metaflow specific environment variables
    # These are only for production, since Codebuild runs in our production VPC
    # These are only used if the build is for the main branch
    METAFLOW_BATCH_JOB_QUEUE: 'CodeBuild/Metaflow:METAFLOW_BATCH_JOB_QUEUE'
    METAFLOW_DATASTORE_SYSROOT_S3: 'CodeBuild/Metaflow:METAFLOW_DATASTORE_SYSROOT_S3'
    METAFLOW_DATATOOLS_SYSROOT_S3: 'CodeBuild/Metaflow:METAFLOW_DATATOOLS_SYSROOT_S3'
    METAFLOW_DEFAULT_DATASTORE: 'CodeBuild/Metaflow:METAFLOW_DEFAULT_DATASTORE'
    METAFLOW_DEFAULT_METADATA: 'CodeBuild/Metaflow:METAFLOW_DEFAULT_METADATA'
    METAFLOW_ECS_S3_ACCESS_IAM_ROLE: 'CodeBuild/Metaflow:METAFLOW_ECS_S3_ACCESS_IAM_ROLE'
    METAFLOW_EVENTS_SFN_ACCESS_IAM_ROLE: 'CodeBuild/Metaflow:METAFLOW_EVENTS_SFN_ACCESS_IAM_ROLE'
    METAFLOW_SERVICE_INTERNAL_URL: 'CodeBuild/Metaflow:METAFLOW_SERVICE_INTERNAL_URL'
    METAFLOW_SERVICE_URL: 'CodeBuild/Metaflow:METAFLOW_SERVICE_URL'
    METAFLOW_SFN_DYNAMO_DB_TABLE: 'CodeBuild/Metaflow:METAFLOW_SFN_DYNAMO_DB_TABLE'
    METAFLOW_SFN_IAM_ROLE: 'CodeBuild/Metaflow:METAFLOW_SFN_IAM_ROLE'
    METAFLOW_DEPLOY_TAG: 'CodeBuild/Metaflow:METAFLOW_DEPLOY_TAG'

#All phases are ran within the hashicorp/terraform:light docker image
phases:
  install:
    commands:
      - echo Installing JQ, AWS CLI, Perl Utils, Node, NPM
      # Within our terraform files we execute jq, and aws-cli and python
      - apt-get -qq update && apt-get -qq install jq nodejs npm curl wget > /dev/null
      # Install conda.
      - wget -nv https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && bash Miniconda3-latest-Linux-x86_64.sh -b  -p $HOME/miniconda
      # Install pipenv and we need to ignore what exists because distutils does not uninstall
      # https://github.com/pypa/virtualenv/issues/1907
      - pip install pipenv

  pre_build:
    commands:
      - echo Setting Up Terraform Token
      - rc="credentials \"app.terraform.io\" { "
      - rc="${rc} token=\"$TERRAFORM_TOKEN\" "
      - rc="${rc}}"
      - echo "$rc" > ~/.terraformrc
      - echo Setting Github Access Token
      - echo "//npm.pkg.github.com/:_authToken=${GITHUB_ACCESS_TOKEN}" > ~/.npmrc
      - echo Setting environment variables
      - cd .aws

      # Until we use a docker image with tfenv built in lets install it.
      # This lets us store the needed terraform verison in the source and not rely on changing amazon values.
      - rm -rf /bin/terraform
      - git clone https://github.com/tfutils/tfenv.git ~/.tfenv
      - ln -s ~/.tfenv/bin/* /usr/bin
      - tfenv install
      - tfenv use $(cat .terraform-version)

      - npm install
      - npm run get
      - npm run build
      # synthesize the js into terraform json with the proper node environment
      - 'if [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$DEV_BRANCH" ]; then NODE_ENV=development npm run synth; else npm run synth; fi'
      - cd cdktf.out
      - rm -rf .terraform # remove sym-link to ../.terraform (if this sym-link exists, terraform doesn't apply correctly. hmmmm)
      - terraform init
  build:
    commands:
      - echo Build started on `date`
      ### If the branch is not main and its not dev, lets do a plan on prod.
      - 'if [ "$CODEBUILD_WEBHOOK_HEAD_REF" != "$MAIN_BRANCH" ] && [ "$CODEBUILD_WEBHOOK_HEAD_REF" != "$DEV_BRANCH" ]; then terraform plan -lock=false -refresh=false -no-color; fi'
      #### If the branch is dev, lets do an apply on dev.
      - 'if [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$DEV_BRANCH" ]; then TF_WORKSPACE=$TF_DEV_WORKSPACE TF_LOG=INFO terraform apply -auto-approve -no-color; fi'
      #### If the branch is main lets apply.
      - 'if [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$MAIN_BRANCH" ]; then terraform apply -auto-approve -no-color; fi'

      # CD back to the project directory root
      - cd ../../

      # Install conda
      - source "$HOME/miniconda/etc/profile.d/conda.sh"
      - hash -r
      - conda config --append channels conda-forge

      # Install our deployment packages so we can run metaflow
      # TODO: see if theres a way in pipenv to just have a --metaflow that will install only metaflow packages
      # so we can remove gcc and python3-dev
      - pipenv install --deploy

      - python jobs/AlgorithmicCandidatesFlow.py --environment=conda check

      #### If the branch is main lets generate our metaflow functions
      - 'if [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$MAIN_BRANCH" ] || [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$DEV_BRANCH" ]; then pipenv run python jobs/AlgorithmicCandidatesFlow.py --environment=conda --with retry step-functions create --tag $METAFLOW_DEPLOY_TAG; fi'
      - 'if [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$MAIN_BRANCH" ] || [ "$CODEBUILD_WEBHOOK_HEAD_REF" == "$DEV_BRANCH" ]; then pipenv run python jobs/CuratedCandidatesFlow.py --environment=conda --with retry step-functions create --tag $METAFLOW_DEPLOY_TAG; fi'
  post_build:
    commands:
      - echo Build completed on `date`
